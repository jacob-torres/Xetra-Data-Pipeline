{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3a3e53",
   "metadata": {},
   "source": [
    "# Daily Reporting Functions for Deutsche Boerse Xetra Dataset\n",
    "\n",
    "A daily summary report is generated by extracting CSV data from the Deutsche Boerse public S3 bucket. The data is then wrangled, aggregated, and stored in a separate bucket in [Apache parque format](https://parquet.apache.org/).\n",
    "\n",
    "Note: Data from the previous day is also used to ensure a significant volume of data is collected. This is in case it's the weekend or a holiday, during which the markets are closed.\n",
    "\n",
    "---\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fed4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from io import StringIO, BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a88226",
   "metadata": {},
   "source": [
    "## ETL Functions\n",
    "\n",
    "### Adapter Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867a580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_df(bucket, key, decoding='utf-8', sep=','):\n",
    "    \"\"\"Reads data from a csv object to a Pandas dataframe.\"\"\"\n",
    "    csv_obj = bucket.Object(key=key).get().get('Body').read().decode(decoding)\n",
    "    data = StringIO(csv_obj)\n",
    "    df = pd.read_csv(data, delimiter=sep)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_df_to_s3(bucket, key, df, format='csv'):\n",
    "    \"\"\"Writes dataframe to a target S3 bucket.\"\"\"\n",
    "\n",
    "    out_buffer = BytesIO()\n",
    "\n",
    "    if format == 'csv':\n",
    "        df.to_csv(out_buffer, index=False)\n",
    "\n",
    "    elif format == 'parquet':\n",
    "        df.to_parquet(out_buffer, index=False)\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: {format} is not a valid format. It should be 'csv' or 'parquet.'\")\n",
    "        return False\n",
    "\n",
    "    bucket.put_object(Body=out_buffer.getvalue(), Key=key)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def list_files_in_prefix(bucket, prefix):\n",
    "    \"\"\"Generates a list of csv files for the given prefix.\"\"\"\n",
    "    files = [obj.key for obj in bucket.objects.filter(Prefix=prefix)]\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a1ee29",
   "metadata": {},
   "source": [
    "### Application Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a84e1ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(bucket, date_list):\n",
    "    \"\"\"Extracts data from the Deutsche Boerse S3 bucket.\"\"\"\n",
    "\n",
    "    # Uses the list_files_in_prefix method to get all CSV files \n",
    "# loaded to the bucket since the specified date.\n",
    "    files = [key for date in date_list for key in list_files_in_prefix(bucket, date)]\n",
    "\n",
    "    try:\n",
    "        df = pd.concat([read_csv_to_df(bucket, obj) for obj in files], ignore_index=True)\n",
    "\n",
    "    except ValueError:\n",
    "        # Instantiate empty dataframe with the expected columns\n",
    "        df =  pd.DataFrame(\n",
    "            columns=[\n",
    "                'ISIN', 'Date', 'Time', 'StartPrice',\n",
    "                'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume'\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def transform(df, columns, arg_date):\n",
    "    \"\"\"Transforms the Xetra data into a form suitable for reporting.\"\"\"\n",
    "\n",
    "    df = df.loc[:, columns]\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # The opening_price column is created by sorting the data by Time,\n",
    "    # then grouping it by ISIN and Date, selecting StartPrice,\n",
    "    # and finally transforming the column to contain only the first date\n",
    "    df['opening_price'] = df.sort_values(\n",
    "        by=['Time']).groupby(\n",
    "        ['ISIN', 'Date'])['StartPrice'].transform('first')\n",
    "\n",
    "    # The closing_price column is created by transforming the data\n",
    "    # similarly to opening_price, but selecting for the last date instead\n",
    "    df['closing_price'] = df.sort_values(\n",
    "        by=['Time']).groupby(\n",
    "        ['ISIN', 'Date'])['StartPrice'].transform('last')\n",
    "\n",
    "    # The dataframe is grouped by ISIN and Date, then aggregated to create\n",
    "    # new columns to express opening, closing, min, max, and trade volume\n",
    "    df = df.groupby(['ISIN', 'Date'], as_index=False).agg(\n",
    "        opening_price_eur=('opening_price', 'min'),\n",
    "        closing_price_eur=('closing_price', 'min'),\n",
    "        minimum_price_eur=('MinPrice', 'min'),\n",
    "        maximum_price_eur=('MaxPrice', 'max'),\n",
    "        daily_traded_volume=('TradedVolume', 'sum'))\n",
    "\n",
    "    # The prev_closing_price column is created\n",
    "    # by sorting the data by Date, and then grouping it by ISIN\n",
    "    # and selecting for closing_price_eur of the previous date\n",
    "    df['prev_closing_price'] = df.sort_values(\n",
    "        by=['Date']).groupby(\n",
    "        ['ISIN'])['opening_price_eur'].shift(1)\n",
    "\n",
    "    # The change_prev_closing_percent column is created\n",
    "    # by subtracting the current and prev closing prices\n",
    "    # and dividing the result by the prev price times 100. This results in\n",
    "    # the percentage of change in the closing price since the last date\n",
    "    df['change_prev_closing_%'] = (\n",
    "        df['opening_price_eur'] - df['prev_closing_price']\n",
    "        ) / df['prev_closing_price'] * 100\n",
    "\n",
    "    df.drop(columns=['prev_closing_price'], inplace=True)\n",
    "    df = df.round(decimals=2)\n",
    "    df = df[df.Date >= arg_date]\n",
    "\n",
    "    return df\n",
    "\n",
    "def load(bucket, df, tgt_key, tgt_format, meta_key, extract_date_list):\n",
    "    \"\"\"Loads the data into a new S3 bucket for reporting.\"\"\"\n",
    "\n",
    "    key = f\"{tgt_key}_{datetime.today().strftime('%Y%m%d_%H%M%S')}.{tgt_format}\"\n",
    "\n",
    "    if len(df) < 1:\n",
    "        print(\"Sorry, no data was extracted. Try another date.\")\n",
    "        return False\n",
    "\n",
    "    write_df_to_s3(bucket, key, df, format=tgt_format)\n",
    "    update_meta_file(bucket, meta_key, extract_date_list)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def report(src_bucket, tgt_bucket, date_list, columns, arg_date, tgt_key, tgt_format, meta_key):\n",
    "    \"\"\"Processes Xetra source data through ETL into a report.\"\"\"\n",
    "\n",
    "    df = extract(src_bucket, date_list)\n",
    "    df = transform(df, columns, arg_date)\n",
    "    extract_date_list = [date for date in date_list if date >= arg_date]\n",
    "    load(tgt_bucket, df, tgt_key, tgt_format, meta_key, extract_date_list)\n",
    "\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7228a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_list(bucket, arg_date, date_format, meta_key):\n",
    "    \"\"\"Returns a list of possible dates based on the argument date.\"\"\"\n",
    "\n",
    "    # Set the minimum date to the previous day (in datetime format)\n",
    "    min_date = datetime.strptime(arg_date, date_format).date() - timedelta(days=1)\n",
    "    today = datetime.today().date()\n",
    "\n",
    "    try:\n",
    "        # Read the meta file in the target S3 bucket\n",
    "        df_meta = read_csv_to_df(bucket, meta_key)\n",
    "\n",
    "        # The date list counts up from min_date to the current date\n",
    "        dates = [(min_date + timedelta(days=x)) for x in range(0, (today-min_date).days + 1)]\n",
    "\n",
    "        # Create set of unique dates in the meta file\n",
    "        # and convert them to pandas datetime objects\n",
    "        src_dates = set(pd.to_datetime(df_meta['source_date']).dt.date)\n",
    "\n",
    "        # Finds list of dates not yet added to the meta file\n",
    "        missing_dates = set(dates[1:]) - src_dates\n",
    "\n",
    "        if missing_dates:\n",
    "            # Set min_date to the day before first date not in the meta file\n",
    "            min_date = min(set(dates[1:]) - src_dates) - timedelta(days=1)\n",
    "            date_results = [date.strftime(date_format) for date in dates if date >= min_date]\n",
    "            min_date_result = (min_date + timedelta(days=1)).strftime(date_format)\n",
    "\n",
    "        else:\n",
    "            date_results = []\n",
    "            min_date_result = datetime(2500, 1, 1).date()\n",
    "\n",
    "    except bucket.session.Session().client('s3').exceptions.NoSuchKey:\n",
    "        date_results = [(min_date + timedelta(days=x)).strftime(date_format) for x in range(0, (today-min_date).days + 1)]\n",
    "        min_date_result = arg_date\n",
    "\n",
    "    return min_date_result, date_results\n",
    "\n",
    "\n",
    "def update_meta_file(bucket, meta_key, extract_date_list):\n",
    "    \"\"\"Updates the meta file with the new dates from the latest report.\"\"\"\n",
    "\n",
    "    df_new = pd.DataFrame(columns=['source_date', 'datetime_of_processing'])\n",
    "    df_new['source_date'] = extract_date_list\n",
    "    df_new['datetime_of_processing'] = datetime.today().strftime('%Y-%m-%d')\n",
    "    df_old = read_csv_to_df(bucket, meta_key)\n",
    "    df_all = pd.concat([df_old, df_new])\n",
    "\n",
    "    write_df_to_s3(bucket, meta_key, df_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d47ce8",
   "metadata": {},
   "source": [
    "## Driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bdad4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Use random date to run the application\n",
    "    date_format = '%Y-%m-%d'\n",
    "    arg_date = '2022-05-12'\n",
    "\n",
    "    # Define bucket and meta values\n",
    "    src_bucket_name = 'deutsche-boerse-xetra-pds'\n",
    "    tgt_bucket_name = 'xetra-data-jt'\n",
    "    tgt_key = 'xetra_daily_report'\n",
    "    tgt_format = 'parquet'\n",
    "    meta_key = 'meta.csv'\n",
    "\n",
    "    # Columns included in the report\n",
    "    columns = ['ISIN', 'Date', 'Time', 'StartPrice',\n",
    "        'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume']\n",
    "\n",
    "    # Initialize the S3 buckets\n",
    "    s3 = boto3.resource('s3')\n",
    "    src_bucket = s3.Bucket(src_bucket_name)\n",
    "    tgt_bucket = s3.Bucket(tgt_bucket_name)\n",
    "\n",
    "    # Run the application\n",
    "    extract_date, date_list = get_date_list(\n",
    "        tgt_bucket, arg_date, date_format, meta_key\n",
    "    )\n",
    "\n",
    "    report(src_bucket, tgt_bucket, date_list, columns,\n",
    "        extract_date, tgt_key, tgt_format, meta_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fdc1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to run the ETL job\n",
    "# and generate the most recent daily report\n",
    "\n",
    "#main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c954d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Display Most Recent Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc78ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 reports in the bucket\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['meta.csv',\n",
       " 'xetra_daily_report_20220510_205428.parquet',\n",
       " 'xetra_daily_report_20220511_075427.parquet',\n",
       " 'xetra_daily_report_20220516_194048.parquet',\n",
       " 'xetra_daily_report_20220516_194335.parquet',\n",
       " 'xetra_daily_report_20220516_194528.parquet']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = 'xetra-data-jt'\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "key_list = [obj.key for obj in bucket.objects.all()]\n",
    "\n",
    "print(f\"There are {len(key_list) - 1} reports in the bucket\")\n",
    "list(key_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f11fda93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>opening_price_eur</th>\n",
       "      <th>closing_price_eur</th>\n",
       "      <th>minimum_price_eur</th>\n",
       "      <th>maximum_price_eur</th>\n",
       "      <th>daily_traded_volume</th>\n",
       "      <th>change_prev_closing_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>36.30</td>\n",
       "      <td>35.80</td>\n",
       "      <td>35.80</td>\n",
       "      <td>36.30</td>\n",
       "      <td>295</td>\n",
       "      <td>-1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>36.75</td>\n",
       "      <td>39.10</td>\n",
       "      <td>36.75</td>\n",
       "      <td>39.30</td>\n",
       "      <td>1307</td>\n",
       "      <td>9.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT00000FACC2</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>7.42</td>\n",
       "      <td>7.35</td>\n",
       "      <td>7.22</td>\n",
       "      <td>7.46</td>\n",
       "      <td>3400</td>\n",
       "      <td>-2.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT0000606306</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>11.22</td>\n",
       "      <td>11.84</td>\n",
       "      <td>11.22</td>\n",
       "      <td>12.09</td>\n",
       "      <td>39371</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT0000606306</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>12.22</td>\n",
       "      <td>12.11</td>\n",
       "      <td>11.90</td>\n",
       "      <td>12.34</td>\n",
       "      <td>40887</td>\n",
       "      <td>2.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>XS2427474023</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>19.10</td>\n",
       "      <td>18.51</td>\n",
       "      <td>18.51</td>\n",
       "      <td>19.10</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6614</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.58</td>\n",
       "      <td>2.80</td>\n",
       "      <td>9968</td>\n",
       "      <td>-4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.97</td>\n",
       "      <td>33613</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616</th>\n",
       "      <td>XS2437455608</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>28.86</td>\n",
       "      <td>27.77</td>\n",
       "      <td>27.77</td>\n",
       "      <td>28.93</td>\n",
       "      <td>0</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6617</th>\n",
       "      <td>XS2437455608</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>25.94</td>\n",
       "      <td>24.91</td>\n",
       "      <td>24.91</td>\n",
       "      <td>25.94</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6618 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISIN        Date  opening_price_eur  closing_price_eur  \\\n",
       "0     AT000000STR1  2022-05-12              36.30              35.80   \n",
       "1     AT000000STR1  2022-05-13              36.75              39.10   \n",
       "2     AT00000FACC2  2022-05-12               7.42               7.35   \n",
       "3     AT0000606306  2022-05-12              11.22              11.84   \n",
       "4     AT0000606306  2022-05-13              12.22              12.11   \n",
       "...            ...         ...                ...                ...   \n",
       "6613  XS2427474023  2022-05-13              19.10              18.51   \n",
       "6614  XS2434891219  2022-05-12               2.76               2.80   \n",
       "6615  XS2434891219  2022-05-13               2.90               2.91   \n",
       "6616  XS2437455608  2022-05-12              28.86              27.77   \n",
       "6617  XS2437455608  2022-05-13              25.94              24.91   \n",
       "\n",
       "      minimum_price_eur  maximum_price_eur  daily_traded_volume  \\\n",
       "0                 35.80              36.30                  295   \n",
       "1                 36.75              39.30                 1307   \n",
       "2                  7.22               7.46                 3400   \n",
       "3                 11.22              12.09                39371   \n",
       "4                 11.90              12.34                40887   \n",
       "...                 ...                ...                  ...   \n",
       "6613              18.51              19.10                    0   \n",
       "6614               2.58               2.80                 9968   \n",
       "6615               2.90               2.97                33613   \n",
       "6616              27.77              28.93                    0   \n",
       "6617              24.91              25.94                    0   \n",
       "\n",
       "      change_prev_closing_%  \n",
       "0                     -1.38  \n",
       "1                      9.22  \n",
       "2                     -2.26  \n",
       "3                      2.25  \n",
       "4                      2.28  \n",
       "...                     ...  \n",
       "6613                  -5.86  \n",
       "6614                  -4.63  \n",
       "6615                   3.96  \n",
       "6616                   1.39  \n",
       "6617                 -10.29  \n",
       "\n",
       "[6618 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the most recent daily report\n",
    "key = key_list[-1]\n",
    "prq_obj = bucket.Object(key=key).get().get('Body').read()\n",
    "data = BytesIO(prq_obj)\n",
    "df_report = pd.read_parquet(data)\n",
    "\n",
    "display(df_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad58ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xetra_etl-lA4dxfWQ",
   "language": "python",
   "name": "xetra_etl-la4dxfwq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
